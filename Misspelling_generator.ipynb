{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from random import randint\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import random\n",
        "\n",
        "CHARS = list('abcdefghijklmnopqrstuvwxyz')\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "def speling_erors_1(token):\n",
        "    if len(token) < 3:\n",
        "        return token\n",
        "\n",
        "    random_char_index = np.random.randint(len(token))\n",
        "    token = token[:random_char_index] + np.random.choice(CHARS) \\\n",
        "            + token[random_char_index + 1:]\n",
        "    return token\n",
        "\n",
        "def speling_erors_2(token):\n",
        "    if len(token) < 3:\n",
        "        return token\n",
        "\n",
        "    random_char_index = np.random.randint(len(token))\n",
        "    token = token[:random_char_index] + token[random_char_index + 1:]\n",
        "  \n",
        "    return token\n",
        "\n",
        "def speling_erors_3(token):\n",
        "    if len(token) < 3:\n",
        "        return token\n",
        "\n",
        "    random_char_index = np.random.randint(len(token))\n",
        "    token = token[:random_char_index] + np.random.choice(CHARS) \\\n",
        "            + token[random_char_index:]\n",
        "    return token\n",
        "\n",
        "def speling_erors_4(token):\n",
        "    if len(token) < 3:\n",
        "        return token\n",
        "\n",
        "    random_char_index = np.random.randint(len(token) - 1)\n",
        "    token = token[:random_char_index]  + token[random_char_index + 1] \\\n",
        "            + token[random_char_index] + token[random_char_index + 2:]        \n",
        "  \n",
        "    return token\n",
        "\n",
        "def speling_erors_5(token):\n",
        "    if len(token) < 3:\n",
        "        return token\n",
        "    random_char_index = np.random.randint(len(token) - 1)\n",
        "    random_char_index2 = np.random.randint(len(token) - 1)\n",
        "\n",
        "    token = token[:random_char_index]  + token[random_char_index + 1] \\\n",
        "            + token[random_char_index] + token[random_char_index + 2:]\\\n",
        "            \n",
        "    token = token[:random_char_index2]  + token[random_char_index2 + 1] \\\n",
        "            + token[random_char_index2] + token[random_char_index2 + 2:]\\\n",
        "        \n",
        "    return token\n",
        "\n",
        "def correct_word(token):\n",
        "    return token\n",
        "\n",
        "\n",
        "def transform(tokens, error_rate=0.3, shuffle=True):\n",
        "    if shuffle:\n",
        "        np.random.shuffle(tokens)\n",
        "        \n",
        "    misspelled_list=[]\n",
        "    for token in tokens:\n",
        "        misspelling1 = speling_erors_1(token)\n",
        "        misspelling2 = speling_erors_2(token,)\n",
        "        misspelling3 = speling_erors_3(token)\n",
        "        misspelling4 = speling_erors_4(token)\n",
        "        misspelling5= speling_erors_5(token)\n",
        "        misspelling6=n_gram(token)\n",
        "\n",
        "        misspelled_list.append(misspelling1)\n",
        "        misspelled_list.append(misspelling2)\n",
        "        misspelled_list.append(misspelling3)\n",
        "        misspelled_list.append(misspelling4)\n",
        "        misspelled_list.append(misspelling5)\n",
        "\n",
        "        for word in misspelling6:\n",
        "          misspelled_list.append(word) \n",
        "\n",
        "        #misspelled_list.append(misspelling6)\n",
        "    return misspelled_list\n",
        "\n",
        "\n",
        "def shuffle(s):\n",
        "    n = len(s)  \n",
        "    li = list(s)\n",
        "    for i in range(0,n-1): \n",
        "        pos = randint(i+1,n-1) \n",
        "        li[pos],li[i] = li[i],li[pos] \n",
        "    res = \"\" \n",
        "    for i in range(n):\n",
        "        res = res + li[i]\n",
        "    return res\n",
        "\n",
        "        \n",
        "def n_gram(token):\n",
        "    corpus = [\n",
        "        token\n",
        "     ]\n",
        "    if len(token)>=6:\n",
        "        vectorizer = CountVectorizer(analyzer='char', ngram_range=(len(token)-2, len(token)))\n",
        "        X = vectorizer.fit_transform(corpus)\n",
        "        gramed=vectorizer.get_feature_names()\n",
        "    elif len(token)==5:\n",
        "        vectorizer = CountVectorizer(analyzer='char', ngram_range=(len(token)-1, len(token)))\n",
        "        X = vectorizer.fit_transform(corpus)\n",
        "        gramed=vectorizer.get_feature_names()\n",
        "    else:\n",
        "        gramed = shuffle(token)\n",
        "\n",
        "    return gramed\n",
        "        \n",
        "        \n",
        "tokens=[\"bereavement\",\"maternity\",\"education\"]\n",
        "transform(tokens, shuffle=True)"
      ],
      "metadata": {
        "id": "WCYc9n8GWHNf",
        "outputId": "53a2c34f-e7f6-4e47-ab9e-8fff2ea0cc3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bereyvement',\n",
              " 'bereavemet',\n",
              " 'bxereavement',\n",
              " 'bereavemetn',\n",
              " 'bereavmenet',\n",
              " 'bereaveme',\n",
              " 'bereavemen',\n",
              " 'bereavement',\n",
              " 'ereavemen',\n",
              " 'ereavement',\n",
              " 'reavement',\n",
              " 'faternity',\n",
              " 'aternity',\n",
              " 'maternpity',\n",
              " 'maetrnity',\n",
              " 'amtrenity',\n",
              " 'aternit',\n",
              " 'aternity',\n",
              " 'materni',\n",
              " 'maternit',\n",
              " 'maternity',\n",
              " 'ternity',\n",
              " 'educacion',\n",
              " 'educaton',\n",
              " 'eduhcation',\n",
              " 'eduaction',\n",
              " 'duecation',\n",
              " 'ducatio',\n",
              " 'ducation',\n",
              " 'educati',\n",
              " 'educatio',\n",
              " 'education',\n",
              " 'ucation']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JM9uitQVW4xZ"
      },
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Making the Most of your Colab Subscription",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}